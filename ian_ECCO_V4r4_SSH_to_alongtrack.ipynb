{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "saving-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import h5py\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import requests\n",
    "import boto3\n",
    "import s3fs\n",
    "from os.path import dirname, join\n",
    "from pprint import pprint\n",
    "from pyresample import kd_tree, geometry, utils\n",
    "from pyresample.geometry import GridDefinition\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-sarah",
   "metadata": {},
   "source": [
    "### Confirm Existence of .netrc file in your home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "religious-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a .netrc file in your home directory with the following\n",
    "# machine urs.earthdata.nasa.gov login ifenty password XCfK5QhgEGuWVgu4qRuH\n",
    "# for login and password use your EarthData login\n",
    "\n",
    "# if this command returns 1, you are good\n",
    "\n",
    "#to create .netrc file, type in terminal: echo \"machine urs.earthdata.nasa.gov login severinf password Calin0852\" > ~/.netrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surprising-pension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "!cat ~/.netrc | grep 'urs.earthdata.nasa.gov' | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-lunch",
   "metadata": {},
   "source": [
    "### Get credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "structural-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import requests\n",
    "\n",
    "def store_aws_keys(endpoint: str=\"https://archive.podaac.earthdata.nasa.gov/s3credentials\"):    \n",
    "    with requests.get(endpoint, \"w\") as r:\n",
    "        accessKeyId, secretAccessKey, sessionToken, expiration = list(r.json().values())\n",
    "\n",
    "    creds ={}\n",
    "    creds['AccessKeyId'] = accessKeyId\n",
    "    creds['SecretAccessKey'] = secretAccessKey\n",
    "    creds['SessionToken'] = sessionToken\n",
    "    creds['expiration'] = expiration\n",
    "    \n",
    "    return creds\n",
    "\n",
    "creds = store_aws_keys()\n",
    "print(creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "north-slovenia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The current session token expires at 2022-03-22 17:58:24+00:00.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nThe current session token expires at {creds['expiration']}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-rocket",
   "metadata": {},
   "source": [
    "# Define important params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "finite-sessions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/efs/ifenty\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/efs/ifenty/ECCO_V4r4_alongtrack_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# output directory\u001b[39;00m\n\u001b[1;32m      7\u001b[0m output_dir\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/efs/ifenty/ECCO_V4r4_alongtrack_output\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(output_dir)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/efs/ifenty/ECCO_V4r4_alongtrack_output'"
     ]
    }
   ],
   "source": [
    "# ECCO Starts on Jan 1, 1992\n",
    "ECCO_start_time= np.datetime64('1992-01-01')\n",
    "alongtrack_file_dir = Path('/efs/ifenty/')\n",
    "print(alongtrack_file_dir)\n",
    "\n",
    "# output directory\n",
    "output_dir=Path('/efs/ifenty/ECCO_V4r4_alongtrack_output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-revision",
   "metadata": {},
   "source": [
    "# Make a map of grid cell areas and calculate total ocean area\n",
    "\n",
    "needed to calculate 'true' global mean sea level from ECCO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-hours",
   "metadata": {},
   "source": [
    "## Download the ECCO grid geometry file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subroutine to download a file from S3 to the local machine\n",
    "def download(source: str):\n",
    "    target = os.path.basename(source.split(\"?\")[0])\n",
    "    \n",
    "    if not os.path.isfile(target):\n",
    "        !wget --quiet --continue --output-document $target $source\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECCO_grid_url = \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/ECCO_L4_GEOMETRY_05DEG_V4R4/GRID_GEOMETRY_ECCO_V4r4_latlon_0p50deg.nc\"\n",
    "ECCO_grid_file = download(ECCO_grid_url)\n",
    "ECCO_grid = xr.open_dataset(ECCO_grid_file)\n",
    "\n",
    "print(ECCO_grid)\n",
    "# we need the area field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-slope",
   "metadata": {},
   "source": [
    "## Make grid cell area for wet points map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask land points\n",
    "ECCO_ocean_area = ECCO_grid.area*ECCO_grid.maskC[0,:]\n",
    "ECCO_ocean_area=ECCO_ocean_area.drop('Z')\n",
    "\n",
    "ECCO_total_ocean_area = ECCO_ocean_area.sum().values\n",
    "\n",
    "# in km^2\n",
    "print(f'total ocean area: {np.round(ECCO_total_ocean_area/1e9)} km^2')\n",
    "ECCO_ocean_area.plot();\n",
    "\n",
    "plt.title('grid cell area [m^2]');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-arrow",
   "metadata": {},
   "source": [
    "# Find the x,y points for each of the cycle days\n",
    "\n",
    "## Load the AlongTrack x,y,t file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "alongtrack = xr.open_dataset(str(alongtrack_file_dir) + '/AlongTrack_sample.nc', decode_times=False)\n",
    "alongtrack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-basketball",
   "metadata": {},
   "source": [
    "## Plot the cycle paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.axes(projection=ccrs.Robinson( \\\n",
    "              central_longitude=-67, globe=None))\n",
    "ax.gridlines()\n",
    "ax.add_feature(cfeature.LAND)\n",
    "#ax.add_feature(cfeature.OCEAN)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "kk=10\n",
    "p=ax.plot(alongtrack.x[::kk],\n",
    "          alongtrack.y[::kk], 'r.', markersize=0.2,\\\n",
    "          transform=ccrs.PlateCarree())\n",
    "\n",
    "# plot x,y locations with nan time\n",
    "ins = np.where(np.isnan(alongtrack.time.values))[0]\n",
    "p=ax.plot(alongtrack.x.values[ins[::10]],\n",
    "          alongtrack.y.values[ins[::10]], 'b.', markersize=5,\\\n",
    "          transform=ccrs.PlateCarree())\n",
    "\n",
    "plt.title('x,y locations for all tracks.  blue=bad time (nan)', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-marking",
   "metadata": {},
   "source": [
    "## Create a dictionary with x,y points for each of the 10 cycle days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alongtrack.time.min())\n",
    "print(alongtrack.time.max())\n",
    "print(len(alongtrack.time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_track_in_d = {}\n",
    "y_track_in_d = {}\n",
    "\n",
    "alongtrack_swath = {}\n",
    "tc = 0\n",
    "all_ins = []\n",
    "for d in range(10):\n",
    "    d_start = d*86400\n",
    "    d_end = d_start + 86400\n",
    "    ins = np.where(np.logical_and(alongtrack.time >= d_start, alongtrack.time < d_end))[0]\n",
    "    \n",
    "    all_ins.append(ins) \n",
    "    x_track_in_d[d],y_track_in_d[d] = utils.check_and_wrap(alongtrack.x[ins],  alongtrack.y[ins])\n",
    "    \n",
    "    print(f'cycle day: {d}, time_start {d_start}s, time_end {d_end}s, number of xy points {len(ins)}')\n",
    "    \n",
    "    tc = tc + len(ins)\n",
    "    # this handy pyresample object will allow us to map from the gridded ECCO fields to the alongtrack points\n",
    "    alongtrack_swath[d] =  geometry.SwathDefinition(lons=x_track_in_d[d], lats=y_track_in_d[d])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note 13,335 time values are Nan!\n",
    "print(f'number of nan times: {np.sum(np.isnan(alongtrack.time.values))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check the range of xy points \n",
    "for d in range(10):\n",
    "    print(f'cycle day {d} min and max longitudes: \\\n",
    "        {np.nanmin(x_track_in_d[d].values), np.nanmax(x_track_in_d[d].values)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-manor",
   "metadata": {},
   "source": [
    "## Plot x,y points for each cycle day with a different color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax = plt.axes(projection=ccrs.Robinson( \\\n",
    "              central_longitude=-67, globe=None))\n",
    "ax.gridlines()\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "kk=10\n",
    "\n",
    "for d in range(10):\n",
    "    p=ax.plot(x_track_in_d[d][::kk],\n",
    "              y_track_in_d[d][::kk],'.', markersize=0.5,\\\n",
    "              transform=ccrs.PlateCarree())\n",
    "\n",
    "plt.title('note gaps from x,y points where time=nan');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-portfolio",
   "metadata": {},
   "source": [
    "# Prepare ECCO Daily SSH dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "ShortName = \"ECCO_L4_SSH_05DEG_DAILY_V4R4B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask PODAAC for the collection id\n",
    "response = requests.get(\n",
    "    url='https://cmr.earthdata.nasa.gov/search/collections.umm_json', \n",
    "    params={'provider': \"POCLOUD\",\n",
    "            'ShortName': ShortName,\n",
    "            'page_size': 1}\n",
    ")\n",
    "\n",
    "ummc = response.json()['items'][0]\n",
    "ccid = ummc['meta']['concept-id']\n",
    "print(f'collection id: {ccid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-graduation",
   "metadata": {},
   "source": [
    "## Make a \"direct connection\" to the S3 file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = s3fs.S3FileSystem(\n",
    "    key=creds['AccessKeyId'],\n",
    "    secret=creds['SecretAccessKey'],\n",
    "    token=creds['SessionToken'],\n",
    "    client_kwargs={'region_name':'us-west-2'},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a S3 'filesystem' object\n",
    "fs = s3fs.S3FileSystem(anon=False,\n",
    "                      key=creds['AccessKeyId'],\n",
    "                      secret=creds['SecretAccessKey'],\n",
    "                      token=creds['SessionToken'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-dragon",
   "metadata": {},
   "source": [
    "## Make a list of all of the ECCO SSH dataset files for some arbitrary year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 1992\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "ECCO_SSH_files = fs.glob(join(\"podaac-ops-cumulus-protected/\", ShortName, '*'+ str(year) + '*.nc'))\n",
    "print(f'time to find urls: { time.time() - start_time} s')\n",
    "print(f'time to find urls: { time.time() - start_time} s')\n",
    "\n",
    "pprint(ECCO_SSH_files[0:5])\n",
    "print('...')\n",
    "pprint(ECCO_SSH_files[-5:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-cursor",
   "metadata": {},
   "source": [
    "## Load all of the files for this year from AWS S3 using 'direct connection' and combine into a single xarray DataSet object\n",
    "\n",
    "Note: this takes a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "\n",
    "# client = Client(\"tcp://127.0.0.1:38643\")\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=[fs.open(f) for f in ECCO_SSH_files]\n",
    "print(paths[0])\n",
    "print(paths[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ECCO_DS_daily = xr.open_mfdataset(\n",
    "    paths=paths,\n",
    "    combine='by_coords',\n",
    "    # concat_dim='time',\n",
    "    decode_cf=True,\n",
    "    coords='minimal',\n",
    "    chunks={'time': 1}  \n",
    ")\n",
    "ECCO_DS_daily.close()\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-engineer",
   "metadata": {},
   "source": [
    "## Extract the dynamic SSH field\n",
    "\n",
    "There are three sea surface height fields in ECCO_DS, we want the dynamic SSH one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECCO_DS_daily\n",
    "ECCO_SSH = ECCO_DS_daily.SSH\n",
    "ECCO_SSH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-paint",
   "metadata": {},
   "source": [
    "# Calculate the 'True' daily GMSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first call sets up the calclation in dask\n",
    "# ... \\sum_i [SSH_i x grid cell area_i] / total grid cell area\n",
    "ECCO_global_mean_sea_level = (ECCO_SSH * ECCO_ocean_area).sum(dim=['latitude','longitude'])/ECCO_total_ocean_area\n",
    "\n",
    "# second call actually computes it\n",
    "ECCO_global_mean_sea_level = ECCO_global_mean_sea_level.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the DataArray Object\n",
    "ECCO_global_mean_sea_level.name = 'ECCO_GMSL'\n",
    "ECCO_global_mean_sea_level.attrs['units'] = 'm'\n",
    "ECCO_global_mean_sea_level.attrs['summary'] = ECCO_DS_daily.attrs['summary']\n",
    "ECCO_global_mean_sea_level.plot();\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Disk\n",
    "fname = output_dir / ('ECCO_V4r4_global_mean_sea_level_' + str(year) + '.nc')\n",
    "ECCO_global_mean_sea_level.to_netcdf(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-galaxy",
   "metadata": {},
   "source": [
    "# Extract along-track SSH from ECCO mapped SSH\n",
    "\n",
    "## Make the GridDefinition object for the mapping procedure (use pyresample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECCO_lons, ECCO_lats = np.meshgrid(ECCO_SSH.longitude, ECCO_SSH.latitude)\n",
    "ECCO_grid_def = GridDefinition(lons=ECCO_lons, lats=ECCO_lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ECCO_lats[0:5])\n",
    "print(ECCO_lons[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-malta",
   "metadata": {},
   "source": [
    "## Loop through all days of the year, map from ECCO to the alongtrack points & Calculate 'true' global mean sea level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note first dimension is time\n",
    "ECCO_SSH.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all days\n",
    "for f in range(len(ECCO_SSH.time)):\n",
    "# get the date/time associated with this record\n",
    "    rec_time = ECCO_SSH.time[f]\n",
    "\n",
    "    # Determine which cycle day we're in\n",
    "    # ... count how many days since 1992-01-01?\n",
    "    delta_days = int((rec_time.values - ECCO_start_time)/1e9/86400)\n",
    "\n",
    "    # ... cycle day is delta_days mod 10\n",
    "    cycle_day = delta_days % 10\n",
    "\n",
    "    print(f'record day of year {str(rec_time.values)[0:10]}, cycle day {cycle_day}')\n",
    "\n",
    "    # sample the ECCO field at the x,y locations for this cycle day \n",
    "    # search within a 200 km radius for the nearest neighbor.\n",
    "    # (overkill since it's a 1 degree model but just to be safe)\n",
    "\n",
    "    ECCO_at_xy_points =\\\n",
    "        kd_tree.resample_nearest(ECCO_grid_def, \\\n",
    "                                 ECCO_SSH[f].values, \\\n",
    "                                 alongtrack_swath[cycle_day],\\\n",
    "                                 radius_of_influence=200000)\n",
    "\n",
    "        # make a new DataArray object\n",
    "    ECCO_at_xy_points_da = xr.DataArray(ECCO_at_xy_points, dims=['i'])\n",
    "    ECCO_at_xy_points_da = ECCO_at_xy_points_da.assign_coords({'time':rec_time})\n",
    "    ECCO_at_xy_points_da = ECCO_at_xy_points_da.assign_coords({'cycle_day':cycle_day})\n",
    "    ECCO_at_xy_points_da = ECCO_at_xy_points_da.assign_coords({'delta_days':delta_days})\n",
    "    ECCO_at_xy_points_da = ECCO_at_xy_points_da.assign_coords({'lon':('i', x_track_in_d[cycle_day].values)})\n",
    "    ECCO_at_xy_points_da = ECCO_at_xy_points_da.assign_coords({'lat':('i', y_track_in_d[cycle_day].values)})\n",
    "    ECCO_at_xy_points_da.delta_days.attrs['comment'] = 'days since 1992-01-01'\n",
    "    ECCO_at_xy_points_da.cycle_day.attrs['comment'] = 'which day in 10 day cycle'\n",
    "\n",
    "    ECCO_at_xy_points_da.name = 'SSH_at_xy'\n",
    "    ECCO_at_xy_points_da.attrs['source']='ECCO V4r4'\n",
    "\n",
    "    # Save to Disk\n",
    "    new_fname = 'ECCO_V4r4_alongtrack_SSH_' + str(rec_time.values).split('T')[0] + '.nc'\n",
    "    ECCO_at_xy_points_da.to_netcdf(output_dir / new_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECCO_at_xy_points_da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-logistics",
   "metadata": {},
   "source": [
    "# Plot Results for One Cycle Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the last processed day \n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "ax=fig.gca()\n",
    "\n",
    "ax = plt.axes(projection=ccrs.Robinson( \\\n",
    "              central_longitude=-67, globe=None))\n",
    "ax.gridlines()\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "#plot 1 point out of 3\n",
    "kk=3\n",
    "p=ax.scatter(ECCO_at_xy_points_da.lon[::kk],\\\n",
    "             ECCO_at_xy_points_da.lat[::kk], \\\n",
    "             c=ECCO_at_xy_points_da[::kk], s=10,\\\n",
    "             transform=ccrs.PlateCarree(),vmin=-1,vmax=1, cmap='jet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the original mapped SSH field \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "ax=fig.gca()\n",
    "\n",
    "ax = plt.axes(projection=ccrs.Robinson( \\\n",
    "              central_longitude=-67, globe=None))\n",
    "ax.gridlines()\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "p=ax.pcolormesh(ECCO_lons, ECCO_lats,ECCO_SSH[f],\n",
    "              transform=ccrs.PlateCarree(), cmap='jet',vmin=-1,vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-vertical",
   "metadata": {},
   "source": [
    "# Plot 10 days of along track SSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECCO_alongtrack_files = np.sort(list(output_dir.glob('*ECCO_V4r4_alongtrack_SSH_' + str(year) + '*nc')))\n",
    "ECCO_alongtrack_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "# any 10 sequential days comprises one full cycle\n",
    "for d in range(10):\n",
    "    tmp.append(xr.open_dataset(ECCO_alongtrack_files[d]))\n",
    "    print(ECCO_alongtrack_files[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "cm = plt.get_cmap('gist_rainbow')\n",
    "ax=fig.gca()\n",
    "\n",
    "ax = plt.axes(projection=ccrs.Robinson( \\\n",
    "              central_longitude=-67, globe=None))\n",
    "ax.gridlines()\n",
    "ax.add_feature(cfeature.LAND)\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "\n",
    "kk=12\n",
    "\n",
    "for d in range(10):\n",
    "    ECCO_at_xy = tmp[d].SSH_at_xy\n",
    "    print(f'adding cycle day {ECCO_at_xy.cycle_day.values}')\n",
    "\n",
    "    p=ax.scatter(ECCO_at_xy.lon[::kk],\\\n",
    "                 ECCO_at_xy.lat[::kk], \\\n",
    "                 c=ECCO_at_xy[::kk], s=1,\\\n",
    "                 transform=ccrs.PlateCarree(),\n",
    "                 vmin=-1,vmax=1, cmap='jet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-space",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
